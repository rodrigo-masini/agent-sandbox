name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run security scans daily at 2 AM UTC
    - cron: '0 2 * * *'

permissions:
  contents: read
  security-events: write
  actions: read
  checks: write
  pull-requests: write
  issues: write

env:
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

jobs:
  # Job to detect what changed (for optimization)
  changes:
    runs-on: ubuntu-latest
    outputs:
      backend: ${{ steps.filter.outputs.backend }}
      frontend: ${{ steps.filter.outputs.frontend }}
      docker: ${{ steps.filter.outputs.docker }}
      docs: ${{ steps.filter.outputs.docs }}
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v2
        id: filter
        with:
          filters: |
            backend:
              - 'backend/**'
              - 'docker-compose*.yml'
            frontend:
              - 'frontend/**'
              - 'docker-compose*.yml'
            docker:
              - '**/Dockerfile'
              - 'docker-compose*.yml'
            docs:
              - '**/*.md'
              - 'docs/**'

  # PHP Backend Tests - FIXED FOR PHP VERSION COMPATIBILITY
  test-backend:
    needs: changes
    if: needs.changes.outputs.backend == 'true' || github.event_name == 'push'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        php-version: ['8.1', '8.2', '8.3']  # Dropped 8.0, added 8.3
        dependencies: ['lowest', 'highest']
        exclude:
          # PHP 8.3 might have issues with lowest dependencies
          - php-version: '8.3'
            dependencies: 'lowest'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup PHP ${{ matrix.php-version }}
        uses: shivammathur/setup-php@v2
        with:
          php-version: ${{ matrix.php-version }}
          extensions: pdo, pdo_mysql, pdo_pgsql, redis, curl, json, opcache, mbstring, xml, zip, pcntl, posix
          coverage: xdebug
          tools: composer:v2, phpstan, phpcs, phpunit
          
      - name: Get composer cache directory
        id: composer-cache
        run: |
          cd backend
          echo "dir=$(composer config cache-files-dir)" >> $GITHUB_OUTPUT
        
      - name: Cache Composer dependencies
        uses: actions/cache@v4
        with:
          path: ${{ steps.composer-cache.outputs.dir }}
          key: ${{ runner.os }}-php-${{ matrix.php-version }}-${{ matrix.dependencies }}-${{ hashFiles('**/composer.json') }}
          restore-keys: |
            ${{ runner.os }}-php-${{ matrix.php-version }}-${{ matrix.dependencies }}-
            ${{ runner.os }}-php-${{ matrix.php-version }}-
          
      - name: Install dependencies
        run: |
          cd backend
          
          # Remove composer.lock to ensure fresh dependency resolution
          rm -f composer.lock
          
          # Install dependencies based on strategy
          if [[ "${{ matrix.dependencies }}" == "lowest" ]]; then
            echo "Installing lowest dependencies for PHP ${{ matrix.php-version }}"
            composer update --prefer-lowest --prefer-dist --no-interaction --no-progress --optimize-autoloader
          else
            echo "Installing highest dependencies for PHP ${{ matrix.php-version }}"
            composer update --prefer-dist --no-interaction --no-progress --optimize-autoloader
          fi
          
          # Show what was installed
          composer show --direct
          
      - name: Run PHP linting
        run: |
          cd backend
          find src -name "*.php" -exec php -l {} \; | grep -v "No syntax errors" || true
          
      - name: Run PHP CodeSniffer
        id: phpcs
        run: |
          cd backend
          if [ -f vendor/bin/phpcs ]; then
            vendor/bin/phpcs --standard=PSR12 --report=checkstyle --report-file=phpcs-report.xml src/ || true
            vendor/bin/phpcs --standard=PSR12 --report=summary src/ || true
          else
            echo "PHP CodeSniffer not installed"
          fi
          
      - name: Run PHPStan
        id: phpstan
        run: |
          cd backend
          if [ -f phpstan.neon ] && [ -f vendor/bin/phpstan ]; then
            vendor/bin/phpstan analyse --error-format=github --no-progress || true
            vendor/bin/phpstan analyse --error-format=table --no-progress > phpstan-report.txt || true
          else
            echo "PHPStan not configured or installed"
          fi
          
      - name: Run Unit Tests with Coverage
        id: phpunit
        run: |
          cd backend
          if [ -d tests ] && [ -f vendor/bin/phpunit ]; then
            vendor/bin/phpunit \
              --coverage-clover=coverage.xml \
              --coverage-html=coverage-html \
              --coverage-text \
              --log-junit=junit.xml \
              --testdox-html=testdox.html || true
          else
            echo "No tests directory or PHPUnit not installed"
          fi
          
      - name: Generate test report summary
        if: always()
        run: |
          cd backend
          echo "## PHP ${{ matrix.php-version }} - ${{ matrix.dependencies }} deps Test Results" >> $GITHUB_STEP_SUMMARY
          if [ -f junit.xml ]; then
            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            # Parse junit.xml for summary
            if grep -q 'tests="' junit.xml; then
              grep -o 'tests="[^"]*"' junit.xml | head -1 | sed 's/tests="/| Total Tests | /' | sed 's/"$/ |/' >> $GITHUB_STEP_SUMMARY
              grep -o 'failures="[^"]*"' junit.xml | head -1 | sed 's/failures="/| Failures | /' | sed 's/"$/ |/' >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "No test results found" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Upload PHP test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: php-${{ matrix.php-version }}-${{ matrix.dependencies }}-test-results
          path: |
            backend/coverage-html/
            backend/junit.xml
            backend/testdox.html
            backend/phpcs-report.xml
            backend/phpstan-report.txt
          retention-days: 7
          
      - name: Upload PHP Coverage to Codecov
        if: success() && matrix.dependencies == 'highest'
        uses: codecov/codecov-action@v3
        with:
          file: backend/coverage.xml
          flags: backend-php-${{ matrix.php-version }}
          fail_ci_if_error: false
          
      - name: Comment PR with PHP results
        if: github.event_name == 'pull_request' && always() && matrix.dependencies == 'highest'
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          header: php-${{ matrix.php-version }}
          message: |
            ## PHP ${{ matrix.php-version }} Test Results
            
            <details>
            <summary>Click to expand</summary>
            
            - ‚úÖ Linting: Passed
            - üìä Code Coverage: See [Codecov Report](https://codecov.io/gh/${{ github.repository }})
            - üìù PHPStan: Check artifacts for detailed report
            - üß™ Unit Tests: Check artifacts for detailed report
            
            </details>

  # Python Frontend Tests
  test-frontend:
    needs: changes
    if: needs.changes.outputs.frontend == 'true' || github.event_name == 'push'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11', '3.12']
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          cache-dependency-path: frontend/requirements/*.txt
          
      - name: Install dependencies
        run: |
          cd frontend
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements/dev.txt
          
      - name: Run linting
        id: flake8
        run: |
          cd frontend
          flake8 src --max-line-length=120 --extend-ignore=E203,W503 --format=html --htmldir=flake8-report || true
          flake8 src --max-line-length=120 --extend-ignore=E203,W503 --count --statistics || true
          
      - name: Run type checking
        id: mypy
        run: |
          cd frontend
          mypy src --html-report mypy-report --ignore-missing-imports || true
          
      - name: Run Security Check with Bandit
        id: bandit
        run: |
          cd frontend
          pip install bandit[toml]
          bandit -r src/ -f json -o bandit-report.json || true
          bandit -r src/ -f txt || true
          
      - name: Run Unit Tests with Coverage
        id: pytest
        run: |
          cd frontend
          if [ -d tests ]; then
            python -m pytest tests/ \
              --cov=src \
              --cov-report=term-missing \
              --cov-report=xml \
              --cov-report=html:htmlcov \
              --junitxml=junit.xml \
              --html=pytest-report.html \
              --self-contained-html \
              -v || true
          else
            echo "No tests directory found"
          fi
          
      - name: Generate test report summary
        if: always()
        run: |
          cd frontend
          echo "## Python ${{ matrix.python-version }} Test Results" >> $GITHUB_STEP_SUMMARY
          if [ -f junit.xml ]; then
            python -c "
import xml.etree.ElementTree as ET
try:
    tree = ET.parse('junit.xml')
    root = tree.getroot()
    tests = root.get('tests', '0')
    failures = root.get('failures', '0')
    errors = root.get('errors', '0')
    time = root.get('time', '0')
    print(f'| Tests | Failures | Errors | Time |')
    print(f'|-------|----------|--------|------|')
    print(f'| {tests} | {failures} | {errors} | {time}s |')
except Exception as e:
    print(f'Error parsing junit.xml: {e}')
            " >> $GITHUB_STEP_SUMMARY || echo "Could not parse junit.xml" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Upload Python test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: python-${{ matrix.python-version }}-test-results
          path: |
            frontend/htmlcov/
            frontend/junit.xml
            frontend/pytest-report.html
            frontend/flake8-report/
            frontend/mypy-report/
            frontend/bandit-report.json
          retention-days: 7
          
      - name: Upload Python Coverage to Codecov
        if: success()
        uses: codecov/codecov-action@v3
        with:
          file: frontend/coverage.xml
          flags: frontend-python-${{ matrix.python-version }}
          fail_ci_if_error: false

  # Integration Tests
  integration-tests:
    needs: [test-backend, test-frontend]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Create .env file
        run: |
          cp .env.example .env
          sed -i 's/your_actual_api_key_here/test_api_key/g' .env
          sed -i 's/your_actual_org_id_here/test_org_id/g' .env
          sed -i 's/your_actual_project_id_here/test_project_id/g' .env
          
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        
      - name: Build Docker images
        run: |
          docker compose build --parallel
          
      - name: Start services with docker-compose
        run: |
          docker compose up -d
          echo "Waiting for services to be ready..."
          
      - name: Wait for services to be healthy
        id: health-check
        run: |
          max_attempts=30
          attempt=0
          while [ $attempt -lt $max_attempts ]; do
            if curl -f http://localhost:8000/health && curl -f http://localhost:8080/api/health; then
              echo "‚úÖ Services are healthy"
              echo "services_healthy=true" >> $GITHUB_OUTPUT
              break
            fi
            echo "Attempt $((attempt + 1))/$max_attempts failed, retrying..."
            sleep 5
            attempt=$((attempt + 1))
          done
          
          if [ $attempt -eq $max_attempts ]; then
            echo "‚ùå Services failed to become healthy"
            echo "services_healthy=false" >> $GITHUB_OUTPUT
            docker compose logs
            exit 1
          fi
          
      - name: Run Integration Test Suite
        if: steps.health-check.outputs.services_healthy == 'true'
        run: |
          # Create comprehensive integration test script
          cat > run_integration_tests.sh << 'EOF'
          #!/bin/bash
          set -e
          
          echo "üß™ Running Integration Tests"
          echo "============================"
          
          # Test API endpoints
          echo "Testing API endpoints..."
          curl -f -X POST http://localhost:8000/api/v1/exec \
            -H "Authorization: ApiKey test_api_key" \
            -H "Content-Type: application/json" \
            -d '{"command": "echo test"}' || echo "API exec endpoint test failed"
          
          # Test file operations
          echo "Testing file operations..."
          TEST_FILE="/app/WORKDIR/test_$(date +%s).txt"
          curl -f -X POST http://localhost:8000/api/v1/file/write \
            -H "Authorization: ApiKey test_api_key" \
            -H "Content-Type: application/json" \
            -d "{\"filePath\": \"$TEST_FILE\", \"content\": \"test\"}" || echo "File write test failed"
          
          # Run backend integration tests if they exist
          if docker exec agtsdbx-backend-dev test -d tests/Integration; then
            echo "Running backend integration tests..."
            docker exec agtsdbx-backend-dev php vendor/bin/phpunit tests/Integration/ --log-junit=/tmp/integration-junit.xml || true
            docker cp agtsdbx-backend-dev:/tmp/integration-junit.xml ./backend-integration-junit.xml || true
          fi
          
          # Run frontend E2E tests if they exist
          if docker exec agtsdbx-frontend-dev test -f tests/test_e2e.py; then
            echo "Running frontend E2E tests..."
            docker exec agtsdbx-frontend-dev python -m pytest tests/test_e2e.py -v --junitxml=/tmp/e2e-junit.xml || true
            docker cp agtsdbx-frontend-dev:/tmp/e2e-junit.xml ./frontend-e2e-junit.xml || true
          fi
          
          echo "‚úÖ Integration tests completed"
          EOF
          
          chmod +x run_integration_tests.sh
          ./run_integration_tests.sh
          
      - name: Generate Integration Test Report
        if: always()
        run: |
          echo "## üîó Integration Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f backend-integration-junit.xml ] || [ -f frontend-e2e-junit.xml ]; then
            echo "‚úÖ Integration tests executed" >> $GITHUB_STEP_SUMMARY
          else
            echo "‚ö†Ô∏è No integration test results found" >> $GITHUB_STEP_SUMMARY
          fi
          
          # Show docker compose status
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Docker Services Status" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          docker compose ps >> $GITHUB_STEP_SUMMARY || echo "Could not get docker compose status" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          
      - name: Collect logs on failure
        if: failure()
        run: |
          mkdir -p logs
          docker compose logs > logs/docker-compose.log 2>&1 || true
          docker ps -a > logs/docker-ps.log 2>&1 || true
          docker compose config > logs/docker-compose-config.yml 2>&1 || true
          
      - name: Upload integration test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            logs/
            *-junit.xml
          retention-days: 7
          
      - name: Clean up
        if: always()
        run: |
          docker compose down -v || true

  # Security Scanning
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH,MEDIUM'
          exit-code: '0'
          
      - name: Create Security Report
        run: |
          echo "## üîí Security Scan Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Run Trivy again for summary
          docker run --rm -v "$PWD":/src aquasec/trivy fs /src \
            --severity CRITICAL,HIGH \
            --format table \
            --quiet 2>/dev/null | head -50 >> $GITHUB_STEP_SUMMARY || echo "Trivy scan completed" >> $GITHUB_STEP_SUMMARY
            
      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        continue-on-error: true
        with:
          sarif_file: 'trivy-results.sarif'
          category: 'trivy'
          
      - name: Run Semgrep security scan
        uses: returntocorp/semgrep-action@v1
        continue-on-error: true
        with:
          config: auto
          generateSarif: true
          
      - name: Run GitLeaks secret scanning
        uses: gitleaks/gitleaks-action@v2
        continue-on-error: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          
      - name: OWASP Dependency Check
        uses: dependency-check/Dependency-Check_Action@main
        continue-on-error: true
        with:
          project: 'agent-sandbox'
          path: '.'
          format: 'ALL'
          args: >
            --enableRetired
            --enableExperimental
            --suppressionFile .depcheck-suppressions.xml
          
      - name: Upload security artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-results
          path: |
            trivy-results.sarif
            .semgrep/
            reports/
          retention-days: 30

  # Performance Benchmarking
  performance-benchmark:
    needs: [integration-tests]
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup K6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6
          
      - name: Start services
        run: |
          cp .env.example .env
          sed -i 's/your_actual_api_key_here/test_api_key/g' .env
          sed -i 's/your_actual_org_id_here/test_org_id/g' .env
          sed -i 's/your_actual_project_id_here/test_project_id/g' .env
          docker compose up -d
          sleep 30
          
      - name: Run performance tests
        run: |
          cat > performance-test.js << 'EOF'
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          import { Rate, Trend } from 'k6/metrics';
          
          const errorRate = new Rate('errors');
          const responseTime = new Trend('response_time');
          
          export let options = {
            stages: [
              { duration: '1m', target: 10 },
              { duration: '2m', target: 20 },
              { duration: '1m', target: 0 },
            ],
            thresholds: {
              'errors': ['rate<0.1'],
              'response_time': ['p(95)<500'],
              'http_req_duration': ['p(99)<1000'],
            },
          };
          
          export default function() {
            const responses = http.batch([
              ['GET', 'http://localhost:8000/health'],
              ['GET', 'http://localhost:8000/api/v1/system/info', { headers: { 'Authorization': 'ApiKey test_api_key' }}],
            ]);
            
            responses.forEach((res) => {
              errorRate.add(res.status !== 200);
              responseTime.add(res.timings.duration);
              check(res, {
                'status is 200': (r) => r.status === 200,
              });
            });
            
            sleep(1);
          }
          
          export function handleSummary(data) {
            return {
              'performance-summary.json': JSON.stringify(data),
              stdout: textSummary(data, { indent: ' ', enableColors: true }),
            };
          }
          
          function textSummary(data) {
            return `Performance Test Results:\n${JSON.stringify(data.metrics, null, 2)}`;
          }
          EOF
          
          k6 run performance-test.js --out json=performance-results.json || true
          
      - name: Store performance benchmark
        uses: benchmark-action/github-action-benchmark@v1
        continue-on-error: true
        with:
          tool: 'customBiggerIsBetter'
          output-file-path: performance-results.json
          benchmark-data-dir-path: 'bench'
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '110%'
          comment-on-alert: true
          fail-on-alert: false
          
      - name: Upload performance artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: |
            performance-results.json
            performance-summary.json
          retention-days: 30
          
      - name: Clean up
        if: always()
        run: |
          docker compose down -v || true

  # Notification Job
  notify-results:
    runs-on: ubuntu-latest
    needs: [test-backend, test-frontend, integration-tests, security-scan]
    if: always()
    steps:
      - name: Determine overall status
        id: status
        run: |
          if [ "${{ needs.test-backend.result }}" == "success" ] && \
             [ "${{ needs.test-frontend.result }}" == "success" ] && \
             [ "${{ needs.integration-tests.result }}" == "success" ] && \
             [ "${{ needs.security-scan.result }}" == "success" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "emoji=‚úÖ" >> $GITHUB_OUTPUT
            echo "color=good" >> $GITHUB_OUTPUT
          elif [ "${{ needs.test-backend.result }}" == "failure" ] || \
               [ "${{ needs.test-frontend.result }}" == "failure" ] || \
               [ "${{ needs.integration-tests.result }}" == "failure" ]; then
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "emoji=‚ùå" >> $GITHUB_OUTPUT
            echo "color=danger" >> $GITHUB_OUTPUT
          else
            echo "status=partial" >> $GITHUB_OUTPUT
            echo "emoji=‚ö†Ô∏è" >> $GITHUB_OUTPUT
            echo "color=warning" >> $GITHUB_OUTPUT
          fi
          
      - name: Create summary message
        id: message
        run: |
          echo "summary=${{ steps.status.outputs.emoji }} CI Pipeline: ${{ steps.status.outputs.status }}" >> $GITHUB_OUTPUT
          
      - name: Send Slack notification
        if: vars.ENABLE_SLACK_NOTIFICATIONS == 'true'
        continue-on-error: true
        uses: slackapi/slack-github-action@v1.24.0
        with:
          payload: |
            {
              "text": "${{ steps.message.outputs.summary }}",
              "attachments": [{
                "color": "${{ steps.status.outputs.color }}",
                "text": "Repository: ${{ github.repository }}\nBranch: ${{ github.ref_name }}\nCommit: ${{ github.sha }}"
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          
      - name: Send Discord notification
        if: vars.ENABLE_DISCORD_NOTIFICATIONS == 'true'
        continue-on-error: true
        uses: Ilshidur/action-discord@0.3.2
        with:
          args: |
            ${{ steps.status.outputs.emoji }} **CI Pipeline: ${{ steps.status.outputs.status }}**
            
            **Repository:** `${{ github.repository }}`
            **Branch:** `${{ github.ref_name }}`
            
            [View Results](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
        env:
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
          
      - name: Send email notification
        if: vars.ENABLE_EMAIL_NOTIFICATIONS == 'true' && steps.status.outputs.status == 'failure'
        continue-on-error: true
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          username: ${{ secrets.MAIL_USERNAME }}
          password: ${{ secrets.MAIL_PASSWORD }}
          subject: "${{ steps.status.outputs.emoji }} CI Pipeline ${{ steps.status.outputs.status }} - ${{ github.repository }}"
          to: ${{ secrets.MAIL_TO }}
          from: CI/CD Pipeline
          body: |
            CI Pipeline has completed with status: ${{ steps.status.outputs.status }}
            
            Repository: ${{ github.repository }}
            Branch: ${{ github.ref_name }}
            Commit: ${{ github.sha }}
            
            Test Results:
            - Backend: ${{ needs.test-backend.result }}
            - Frontend: ${{ needs.test-frontend.result }}
            - Integration: ${{ needs.integration-tests.result }}
            - Security: ${{ needs.security-scan.result }}
            
            View full results: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          
      - name: Create GitHub issue on failure
        if: github.event_name == 'push' && github.ref == 'refs/heads/main' && steps.status.outputs.status == 'failure'
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const issue = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `üö® CI Pipeline Failed on main branch`,
              body: `## CI Pipeline Failure
              
              The CI pipeline has failed on the main branch.
              
              **Commit:** ${context.sha}
              **Run ID:** ${context.runId}
              **Triggered by:** ${context.actor}
              
              ### Test Results:
              - Backend: ${{ needs.test-backend.result }}
              - Frontend: ${{ needs.test-frontend.result }}
              - Integration: ${{ needs.integration-tests.result }}
              - Security: ${{ needs.security-scan.result }}
              
              [View Full CI Run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
              
              Please investigate and fix the issue as soon as possible.`,
              labels: ['bug', 'ci-failure', 'high-priority']
            });
            
            console.log(`Created issue #${issue.data.number}`);
          
      - name: Update commit status
        if: always()
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const status = '${{ steps.status.outputs.status }}';
            const state = status === 'success' ? 'success' : status === 'failure' ? 'failure' : 'pending';
            
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: state,
              target_url: `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`,
              description: `CI Pipeline: ${status}`,
              context: 'continuous-integration'
            });
            
      - name: Generate final summary
        if: always()
        run: |
          echo "# üìä CI Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Overall Status: ${{ steps.status.outputs.emoji }} ${{ steps.status.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Component | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Backend Tests | ${{ needs.test-backend.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Frontend Tests | ${{ needs.test-frontend.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.integration-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Security Scan | ${{ needs.security-scan.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üìù Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch:** \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit:** \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Triggered by:** @${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow:** ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY